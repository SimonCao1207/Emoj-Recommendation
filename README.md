<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#paper">Paper</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#roadmap">Roadmap</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details>

<!-- ABOUT THE PROJECT -->
## About The Project
![alt text](https://github.com/SimonCao1207/Emoji-Recommendation/blob/main/img/pic1.png?raw=true)
Texting, besides talking, has become a main method of communication for more than a decade
even before the pandemic. Along with that trend, the use of emojis in texting is also more and
more popular, especially among the young. A wide variety of emojis have been commonly seen
in different digital contexts including daily messaging, social media platformsâ€™ comments (e.g:
Facebook or Instagram,...) or even in more formal situations namely emails or informative posts.
However, to pick a desired emoji, users often have to scroll over the emoji tab containing
hundreds of choices, which would lead to bad user experiences. Even in a better case, most emojis
recommendations from popular messaging apps, platforms and built-in keys of devices or operating
systems are based on word-based models such as torchMoji or DeepMoji. These, as a result, would
produce emojis regardless of context like negation.
Aware of that situation, our team has designed a sentence-based emoji suggestion, along with
an api so that other developers can utilize our model for their applications. Our model was fine
tuned on pre-train BERT, which has been widely used and performed well in many NLP tasks
including classification.

<p align="right">(<a href="#top">back to top</a>)</p>

### Paper

Visit our paper [here](https://drive.google.com/file/d/1KwyAgc_1gwo7T38B4x2BNCV9PFxrAkT4/view?usp=sharing)

<p align="right">(<a href="#top">back to top</a>)</p>









figure table
Best quantitative result
Best qualitative result
Description:
training:
training code and detail guidline for specific pretrained-model and training method.
predict: produce the output of two best models.
model state dict: 12 fine-tunning model state dicts of pretrained BERT and its variances

Demo web: (Vinh)
